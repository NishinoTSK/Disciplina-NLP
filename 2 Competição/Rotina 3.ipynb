{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Rotina 3.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"TPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S14X2rW6Kr_d","executionInfo":{"status":"ok","timestamp":1621536803018,"user_tz":180,"elapsed":3568,"user":{"displayName":"A Channel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggz2bYNfS9NrAcTdTQF-N55OWSdO1uRFRXC0UCW=s64","userId":"00910252667657358335"}},"outputId":"1e402e16-eded-4357-fed4-c298dc483189"},"source":["!pip install flair"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: flair in /usr/local/lib/python3.7/dist-packages (0.8.0.post1)\n","Requirement already satisfied: transformers>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from flair) (4.6.1)\n","Requirement already satisfied: numpy<1.20.0 in /usr/local/lib/python3.7/dist-packages (from flair) (1.19.5)\n","Requirement already satisfied: gensim<=3.8.3,>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from flair) (3.6.0)\n","Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from flair) (2.8.1)\n","Requirement already satisfied: bpemb>=0.3.2 in /usr/local/lib/python3.7/dist-packages (from flair) (0.3.3)\n","Requirement already satisfied: janome in /usr/local/lib/python3.7/dist-packages (from flair) (0.4.1)\n","Requirement already satisfied: sentencepiece==0.1.95 in /usr/local/lib/python3.7/dist-packages (from flair) (0.1.95)\n","Requirement already satisfied: hyperopt>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from flair) (0.1.2)\n","Requirement already satisfied: sqlitedict>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from flair) (1.7.0)\n","Requirement already satisfied: tqdm>=4.26.0 in /usr/local/lib/python3.7/dist-packages (from flair) (4.41.1)\n","Requirement already satisfied: mpld3==0.3 in /usr/local/lib/python3.7/dist-packages (from flair) (0.3)\n","Requirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.7/dist-packages (from flair) (3.2.2)\n","Requirement already satisfied: ftfy in /usr/local/lib/python3.7/dist-packages (from flair) (6.0.1)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from flair) (0.8.9)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from flair) (0.22.2.post1)\n","Requirement already satisfied: segtok>=1.5.7 in /usr/local/lib/python3.7/dist-packages (from flair) (1.5.10)\n","Requirement already satisfied: deprecated>=1.2.4 in /usr/local/lib/python3.7/dist-packages (from flair) (1.2.12)\n","Requirement already satisfied: langdetect in /usr/local/lib/python3.7/dist-packages (from flair) (1.0.9)\n","Requirement already satisfied: gdown==3.12.2 in /usr/local/lib/python3.7/dist-packages (from flair) (3.12.2)\n","Requirement already satisfied: konoha<5.0.0,>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from flair) (4.6.4)\n","Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.7/dist-packages (from flair) (0.0.9)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from flair) (4.2.6)\n","Requirement already satisfied: torch<=1.7.1,>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from flair) (1.7.1)\n","Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from flair) (2019.12.20)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers>=4.0.0->flair) (3.0.12)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers>=4.0.0->flair) (4.0.1)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers>=4.0.0->flair) (0.0.45)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers>=4.0.0->flair) (2.23.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers>=4.0.0->flair) (20.9)\n","Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.0.0->flair) (0.10.2)\n","Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim<=3.8.3,>=3.4.0->flair) (1.4.1)\n","Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim<=3.8.3,>=3.4.0->flair) (5.0.0)\n","Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim<=3.8.3,>=3.4.0->flair) (1.15.0)\n","Requirement already satisfied: pymongo in /usr/local/lib/python3.7/dist-packages (from hyperopt>=0.1.1->flair) (3.11.4)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from hyperopt>=0.1.1->flair) (2.5.1)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from hyperopt>=0.1.1->flair) (0.16.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->flair) (1.3.1)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->flair) (2.4.7)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->flair) (0.10.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from ftfy->flair) (0.2.5)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->flair) (1.0.1)\n","Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from deprecated>=1.2.4->flair) (1.12.1)\n","Requirement already satisfied: overrides<4.0.0,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from konoha<5.0.0,>=4.0.0->flair) (3.1.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub->flair) (3.7.4.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers>=4.0.0->flair) (3.4.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=4.0.0->flair) (8.0.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=4.0.0->flair) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=4.0.0->flair) (2020.12.5)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=4.0.0->flair) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=4.0.0->flair) (3.0.4)\n","Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx->hyperopt>=0.1.1->flair) (4.4.2)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DV7xtnyrLcIH","executionInfo":{"status":"ok","timestamp":1621536805990,"user_tz":180,"elapsed":6531,"user":{"displayName":"A Channel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggz2bYNfS9NrAcTdTQF-N55OWSdO1uRFRXC0UCW=s64","userId":"00910252667657358335"}}},"source":["from flair.data import Corpus\n","from flair.datasets import ColumnCorpus\n","import pandas as pd\n","import numpy as np"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n-IQHiK8sOIi","executionInfo":{"status":"ok","timestamp":1621536805992,"user_tz":180,"elapsed":6525,"user":{"displayName":"A Channel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggz2bYNfS9NrAcTdTQF-N55OWSdO1uRFRXC0UCW=s64","userId":"00910252667657358335"}},"outputId":"cabd50d3-4af1-4e7f-f95e-c0fa6cddd6f1"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CrhkdVGnPAl-","executionInfo":{"status":"ok","timestamp":1621536811660,"user_tz":180,"elapsed":12185,"user":{"displayName":"A Channel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggz2bYNfS9NrAcTdTQF-N55OWSdO1uRFRXC0UCW=s64","userId":"00910252667657358335"}},"outputId":"b4a602e4-d5a5-4569-d9ec-d42e2bfaa920"},"source":["# define columns\n","columns = {0: 'text', 1: 'ner'}\n","\n","# this is the folder in which train, test and dev files reside\n","data_folder = '/content/drive/MyDrive/NLP/2_Competição/Dataset'\n","\n","# init a corpus using column format, data folder and the names of the train, dev and test files\n","corpus: Corpus = ColumnCorpus(data_folder, columns,\n","                              train_file= 'train.conll',\n","                              test_file= 'test.conll')"],"execution_count":4,"outputs":[{"output_type":"stream","text":["2021-05-20 18:53:17,345 Reading data from /content/drive/MyDrive/NLP/2_Competição/Dataset\n","2021-05-20 18:53:17,346 Train: /content/drive/MyDrive/NLP/2_Competição/Dataset/train.conll\n","2021-05-20 18:53:17,347 Dev: None\n","2021-05-20 18:53:17,348 Test: /content/drive/MyDrive/NLP/2_Competição/Dataset/test.conll\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"I_DLugXUKYob","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1621536212521,"user_tz":180,"elapsed":10363,"user":{"displayName":"A Channel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggz2bYNfS9NrAcTdTQF-N55OWSdO1uRFRXC0UCW=s64","userId":"00910252667657358335"}},"outputId":"3fed1d66-59bf-40f4-c61c-c86889dc6de2"},"source":["from flair.data import Corpus\n","from flair.datasets import CONLL_03\n","from flair.embeddings import TokenEmbeddings, WordEmbeddings, StackedEmbeddings, PooledFlairEmbeddings\n","from flair.embeddings import TransformerWordEmbeddings, DocumentPoolEmbeddings\n","from typing import List\n","from torch.optim.adam import Adam\n","\n","# 2. what tag do we want to predict?\n","tag_type = 'ner'\n","\n","# 3. make the tag dictionary from the corpus\n","tag_dictionary = corpus.make_tag_dictionary(tag_type=tag_type)\n","\n","# initialize embeddings\n","embedding_types: List[TokenEmbeddings] = [\n","\n","    # GloVe embeddings\n","    WordEmbeddings('pt'),\n","\n","    # # contextual string embeddings, forward\n","    PooledFlairEmbeddings('pt-forward', pooling='min'),\n","\n","    # # contextual string embeddings, backward\n","    PooledFlairEmbeddings('pt-backward', pooling='min'),\n","]\n","\n","embeddings: StackedEmbeddings = StackedEmbeddings(embeddings=embedding_types)\n","\n","# initialize sequence tagger\n","from flair.models import SequenceTagger\n","\n","tagger: SequenceTagger = SequenceTagger(hidden_size=256,\n","                                        embeddings=embeddings,\n","                                        tag_dictionary=tag_dictionary,\n","                                        tag_type=tag_type,\n","                                        rnn_layers = 2\n","                                        )\n","\n","# initialize trainer\n","from flair.trainers import ModelTrainer\n","\n","trainer: ModelTrainer = ModelTrainer(tagger, corpus)\n","\n","trainer.train('resources/taggers/nerFinal',\n","              train_with_dev=False,\n","              learning_rate=0.1,\n","              min_learning_rate=0.0001,\n","              mini_batch_size=32,\n","              max_epochs=80)\n"],"execution_count":10,"outputs":[{"output_type":"stream","text":["2021-05-20 18:43:15,032 https://flair.informatik.hu-berlin.de/resources/embeddings/token/pt-wiki-fasttext-300d-1M.vectors.npy not found in cache, downloading to /tmp/tmp2vrw_ub_\n"],"name":"stdout"},{"output_type":"stream","text":["\n","  0%|          | 0/710528528 [00:00<?, ?B/s]\u001b[A\n","  0%|          | 9216/710528528 [00:00<2:23:45, 82370.59B/s]\u001b[A\n","  0%|          | 33792/710528528 [00:00<1:56:51, 101333.02B/s]\u001b[A\n","  0%|          | 91136/710528528 [00:00<1:29:00, 133039.09B/s]\u001b[A\n","  0%|          | 205824/710528528 [00:00<1:05:53, 179689.64B/s]\u001b[A\n","  0%|          | 443392/710528528 [00:00<47:50, 247363.01B/s]  \u001b[A\n","  0%|          | 902144/710528528 [00:00<34:21, 344165.58B/s]\u001b[A\n","  0%|          | 1827840/710528528 [00:00<24:28, 482725.68B/s]\u001b[A\n","  1%|          | 3671040/710528528 [00:00<17:18, 680756.37B/s]\u001b[A\n","  1%|          | 5465088/710528528 [00:01<12:18, 954442.50B/s]\u001b[A\n","  1%|          | 7341056/710528528 [00:01<08:48, 1329849.83B/s]\u001b[A\n","  1%|▏         | 9184256/710528528 [00:01<06:22, 1833940.74B/s]\u001b[A\n","  2%|▏         | 11109376/710528528 [00:01<04:39, 2501388.38B/s]\u001b[A\n","  2%|▏         | 12936192/710528528 [00:01<03:28, 3345543.69B/s]\u001b[A\n","  2%|▏         | 14861312/710528528 [00:01<02:38, 4399739.37B/s]\u001b[A\n","  2%|▏         | 16679936/710528528 [00:01<02:03, 5610207.58B/s]\u001b[A\n","  3%|▎         | 18613248/710528528 [00:01<01:38, 7003199.21B/s]\u001b[A\n","  3%|▎         | 20448256/710528528 [00:01<01:22, 8407828.68B/s]\u001b[A\n","  3%|▎         | 22348800/710528528 [00:02<01:09, 9843460.65B/s]\u001b[A\n","  3%|▎         | 24192000/710528528 [00:02<01:01, 11108266.58B/s]\u001b[A\n","  4%|▎         | 26076160/710528528 [00:02<00:55, 12271171.24B/s]\u001b[A\n","  4%|▍         | 27812864/710528528 [00:02<01:01, 11014194.53B/s]\u001b[A\n","  4%|▍         | 30860288/710528528 [00:02<00:50, 13335395.45B/s]\u001b[A\n","  5%|▍         | 33235968/710528528 [00:02<00:45, 14894669.36B/s]\u001b[A\n","  5%|▍         | 35081216/710528528 [00:02<00:44, 15121444.21B/s]\u001b[A\n","  5%|▌         | 37733376/710528528 [00:02<00:39, 16875669.10B/s]\u001b[A\n","  6%|▌         | 40870912/710528528 [00:03<00:35, 19021186.65B/s]\u001b[A\n","  6%|▌         | 43058176/710528528 [00:03<00:35, 18979524.34B/s]\u001b[A\n","  6%|▋         | 46130176/710528528 [00:03<00:31, 21389796.38B/s]\u001b[A\n","  7%|▋         | 48497664/710528528 [00:03<00:31, 21176566.33B/s]\u001b[A\n","  7%|▋         | 50776064/710528528 [00:03<00:30, 21384016.82B/s]\u001b[A\n","  8%|▊         | 53683200/710528528 [00:03<00:29, 22546717.06B/s]\u001b[A\n","  8%|▊         | 56673280/710528528 [00:03<00:27, 23422389.17B/s]\u001b[A\n","  8%|▊         | 59339776/710528528 [00:03<00:26, 24308909.39B/s]\u001b[A\n","  9%|▊         | 61833216/710528528 [00:03<00:28, 22924356.68B/s]\u001b[A\n","  9%|▉         | 64655360/710528528 [00:04<00:26, 24292027.91B/s]\u001b[A\n","  9%|▉         | 67409920/710528528 [00:04<00:25, 25183895.25B/s]\u001b[A\n"," 10%|▉         | 69982208/710528528 [00:04<00:27, 23510634.53B/s]\u001b[A\n"," 10%|█         | 72442880/710528528 [00:04<00:26, 23817840.05B/s]\u001b[A\n"," 11%|█         | 75121664/710528528 [00:04<00:25, 24636733.53B/s]\u001b[A\n"," 11%|█         | 77623296/710528528 [00:04<00:26, 23648025.45B/s]\u001b[A\n"," 11%|█▏        | 80092160/710528528 [00:04<00:26, 23950787.89B/s]\u001b[A\n"," 12%|█▏        | 82772992/710528528 [00:04<00:25, 24639086.04B/s]\u001b[A\n"," 12%|█▏        | 85260288/710528528 [00:04<00:26, 23918658.70B/s]\u001b[A\n"," 12%|█▏        | 87710720/710528528 [00:05<00:25, 24090640.84B/s]\u001b[A\n"," 13%|█▎        | 90334208/710528528 [00:05<00:25, 24653414.50B/s]\u001b[A\n"," 13%|█▎        | 92813312/710528528 [00:05<00:26, 23747484.31B/s]\u001b[A\n"," 13%|█▎        | 95257600/710528528 [00:05<00:25, 23943830.44B/s]\u001b[A\n"," 14%|█▍        | 97936384/710528528 [00:05<00:24, 24545599.52B/s]\u001b[A\n"," 14%|█▍        | 100885504/710528528 [00:05<00:23, 25844337.93B/s]\u001b[A\n"," 15%|█▍        | 103497728/710528528 [00:05<00:24, 25142470.99B/s]\u001b[A\n"," 15%|█▍        | 106035200/710528528 [00:05<00:25, 23545481.60B/s]\u001b[A\n"," 15%|█▌        | 108774400/710528528 [00:05<00:24, 24403524.54B/s]\u001b[A\n"," 16%|█▌        | 111690752/710528528 [00:05<00:23, 25647452.37B/s]\u001b[A\n"," 16%|█▌        | 114296832/710528528 [00:06<00:24, 23904641.87B/s]\u001b[A\n"," 16%|█▋        | 116755456/710528528 [00:06<00:24, 24105042.16B/s]\u001b[A\n"," 17%|█▋        | 119383040/710528528 [00:06<00:23, 24653209.43B/s]\u001b[A\n"," 17%|█▋        | 121877504/710528528 [00:06<00:24, 24042846.39B/s]\u001b[A\n"," 17%|█▋        | 124327936/710528528 [00:06<00:24, 24179203.92B/s]\u001b[A\n"," 18%|█▊        | 127017984/710528528 [00:06<00:23, 24888992.79B/s]\u001b[A\n"," 18%|█▊        | 129524736/710528528 [00:06<00:24, 23724798.06B/s]\u001b[A\n"," 19%|█▊        | 131920896/710528528 [00:06<00:25, 22941453.56B/s]\u001b[A\n"," 19%|█▉        | 135029760/710528528 [00:06<00:23, 23987691.37B/s]\u001b[A\n"," 19%|█▉        | 137788416/710528528 [00:07<00:22, 24964521.57B/s]\u001b[A\n"," 20%|█▉        | 140314624/710528528 [00:07<00:23, 24014014.97B/s]\u001b[A\n"," 20%|██        | 142744576/710528528 [00:07<00:33, 16739805.31B/s]\u001b[A\n"," 21%|██        | 145802240/710528528 [00:07<00:29, 18847945.42B/s]\u001b[A\n"," 21%|██        | 147999744/710528528 [00:07<00:30, 18702664.68B/s]\u001b[A\n"," 21%|██        | 150537216/710528528 [00:07<00:28, 19708870.46B/s]\u001b[A\n"," 22%|██▏       | 153601024/710528528 [00:07<00:26, 21297719.58B/s]\u001b[A\n"," 22%|██▏       | 156640256/710528528 [00:08<00:24, 22600788.13B/s]\u001b[A\n"," 22%|██▏       | 159030272/710528528 [00:08<00:24, 22668440.58B/s]\u001b[A\n"," 23%|██▎       | 161388544/710528528 [00:08<00:24, 22047294.90B/s]\u001b[A"],"name":"stderr"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-9e32f137ed40>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m# GloVe embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mWordEmbeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m# # contextual string embeddings, forward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/flair/embeddings/token.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, embeddings, field)\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;31m# two-letter language code wiki embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m             \u001b[0mcached_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{hu_path}/{embeddings}-wiki-fasttext-300d-1M.vectors.npy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m             \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcached_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{hu_path}/{embeddings}-wiki-fasttext-300d-1M\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/flair/file_utils.py\u001b[0m in \u001b[0;36mcached_path\u001b[0;34m(url_or_filename, cache_dir)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mparsed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscheme\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"http\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"https\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;31m# URL, so get it from the cache (downloading if necessary)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mget_from_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_or_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mparsed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscheme\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_or_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;31m# File, and it exists.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/flair/file_utils.py\u001b[0m in \u001b[0;36mget_from_cache\u001b[0;34m(url, cache_dir)\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0mprogress\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"B\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtemp_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# filter out keep-alive new chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m                     \u001b[0mprogress\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    749\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'stream'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m                     \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    752\u001b[0m                         \u001b[0;32myield\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mProtocolError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/urllib3/response.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_fp_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecode_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/urllib3/response.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[1;32m    464\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp_bytes_read\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlength_remaining\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlength_remaining\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflush_decoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B5GH-RiYQ4Uh","executionInfo":{"status":"ok","timestamp":1621540393754,"user_tz":180,"elapsed":4599,"user":{"displayName":"A Channel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggz2bYNfS9NrAcTdTQF-N55OWSdO1uRFRXC0UCW=s64","userId":"00910252667657358335"}},"outputId":"cf99b7d3-ea3f-4d35-df2a-a49255f80669"},"source":["from transformers import AutoModel, AutoTokenizer, AutoConfig\n","tokenizer = AutoTokenizer.from_pretrained('neuralmind/bert-base-portuguese-cased')\n","config = AutoConfig.from_pretrained('neuralmind/bert-base-portuguese-cased')\n","model = AutoModel.from_pretrained('neuralmind/bert-base-portuguese-cased', config=config)\n","\n","tokenizer.save_pretrained('/content/drive/MyDrive/NLP/2_Competição/resultados')\n","model.save_pretrained('/content/drive/MyDrive/NLP/2_Competição/resultados')"],"execution_count":15,"outputs":[{"output_type":"stream","text":["Some weights of the model checkpoint at neuralmind/bert-base-portuguese-cased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"b3beip3-nxHK","executionInfo":{"status":"error","timestamp":1621540807947,"user_tz":180,"elapsed":363685,"user":{"displayName":"A Channel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggz2bYNfS9NrAcTdTQF-N55OWSdO1uRFRXC0UCW=s64","userId":"00910252667657358335"}},"outputId":"72d7d8e6-6fc4-45be-f73d-44efe4bd213d"},"source":["from flair.data import Corpus\n","from flair.datasets import CONLL_03\n","from flair.embeddings import TokenEmbeddings, WordEmbeddings, StackedEmbeddings, PooledFlairEmbeddings\n","from flair.embeddings import TransformerWordEmbeddings, DocumentPoolEmbeddings\n","from typing import List\n","from torch.optim.adam import Adam\n","from flair.trainers import ModelTrainer\n","import torch\n","import torchvision\n","from flair.models import SequenceTagger\n","\n","# 2. what tag do we want to predict?\n","tag_type = 'ner'\n","\n","# 3. make the tag dictionary from the corpus\n","tag_dictionary = corpus.make_tag_dictionary(tag_type=tag_type)\n","\n","use_context = 16\n","# hf_model = 'xlm-roberta-large'\n","\n","hf_model = 'neuralmind/bert-base-portuguese-cased'\n","\n","# embeddings = TransformerWordEmbeddings('/content/drive/MyDrive/NLP/2_Competição/resultados')\n","\n","\n","embeddings = TransformerWordEmbeddings(\n","    model=hf_model,\n","    layers=\"-1\",\n","    subtoken_pooling=\"first\",\n","    fine_tune=True,\n",")\n","\n","tagger: SequenceTagger = SequenceTagger(\n","    hidden_size=256,\n","    embeddings=embeddings,\n","    tag_dictionary=tag_dictionary,\n","    tag_type='ner',\n","    use_crf=False,\n","    use_rnn=False,\n","    reproject_embeddings=False,\n",")\n","\n","trainer = ModelTrainer(tagger, corpus, optimizer=torch.optim.AdamW)\n","from torch.optim.lr_scheduler import OneCycleLR\n","\n","context_string = '+context' if use_context else ''\n","\n","trainer.train(f\"resources/flert\",\n","              learning_rate=5.0e-6,\n","              mini_batch_size=4,\n","              mini_batch_chunk_size=1,\n","              max_epochs=5,\n","              scheduler=OneCycleLR,\n","              embeddings_storage_mode='none',\n","              weight_decay=0.,\n","              )"],"execution_count":17,"outputs":[{"output_type":"stream","text":["Some weights of the model checkpoint at neuralmind/bert-base-portuguese-cased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"],"name":"stderr"},{"output_type":"stream","text":["2021-05-20 19:53:58,868 ----------------------------------------------------------------------------------------------------\n","2021-05-20 19:53:58,871 Model: \"SequenceTagger(\n","  (embeddings): TransformerWordEmbeddings(\n","    (model): BertModel(\n","      (embeddings): BertEmbeddings(\n","        (word_embeddings): Embedding(29794, 768, padding_idx=0)\n","        (position_embeddings): Embedding(512, 768)\n","        (token_type_embeddings): Embedding(2, 768)\n","        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (encoder): BertEncoder(\n","        (layer): ModuleList(\n","          (0): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (1): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (2): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (3): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (4): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (5): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (6): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (7): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (8): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (9): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (10): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (11): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","        )\n","      )\n","      (pooler): BertPooler(\n","        (dense): Linear(in_features=768, out_features=768, bias=True)\n","        (activation): Tanh()\n","      )\n","    )\n","  )\n","  (word_dropout): WordDropout(p=0.05)\n","  (locked_dropout): LockedDropout(p=0.5)\n","  (linear): Linear(in_features=768, out_features=17, bias=True)\n","  (beta): 1.0\n","  (weights): None\n","  (weight_tensor) None\n",")\"\n","2021-05-20 19:53:58,873 ----------------------------------------------------------------------------------------------------\n","2021-05-20 19:53:58,875 Corpus: \"Corpus: 6797 train + 755 dev + 2840 test sentences\"\n","2021-05-20 19:53:58,876 ----------------------------------------------------------------------------------------------------\n","2021-05-20 19:53:58,878 Parameters:\n","2021-05-20 19:53:58,881  - learning_rate: \"5e-06\"\n","2021-05-20 19:53:58,882  - mini_batch_size: \"4\"\n","2021-05-20 19:53:58,885  - patience: \"3\"\n","2021-05-20 19:53:58,886  - anneal_factor: \"0.5\"\n","2021-05-20 19:53:58,888  - max_epochs: \"5\"\n","2021-05-20 19:53:58,889  - shuffle: \"True\"\n","2021-05-20 19:53:58,891  - train_with_dev: \"False\"\n","2021-05-20 19:53:58,892  - batch_growth_annealing: \"False\"\n","2021-05-20 19:53:58,894 ----------------------------------------------------------------------------------------------------\n","2021-05-20 19:53:58,896 Model training base path: \"resources/flert\"\n","2021-05-20 19:53:58,897 ----------------------------------------------------------------------------------------------------\n","2021-05-20 19:53:58,899 Device: cpu\n","2021-05-20 19:53:58,900 ----------------------------------------------------------------------------------------------------\n","2021-05-20 19:53:58,903 Embeddings storage mode: none\n","2021-05-20 19:53:58,909 ----------------------------------------------------------------------------------------------------\n","2021-05-20 19:58:39,004 epoch 1 - iter 170/1700 - loss 1.05721540 - samples/sec: 2.43 - lr: 0.000005\n"],"name":"stdout"},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-17-db594bb5b6fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m               \u001b[0mscheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mOneCycleLR\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m               \u001b[0membeddings_storage_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'none'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m               \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m               )\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/flair/trainers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, base_path, learning_rate, mini_batch_size, mini_batch_chunk_size, max_epochs, scheduler, cycle_momentum, anneal_factor, patience, initial_extra_patience, min_learning_rate, train_with_dev, train_with_test, monitor_train, monitor_test, embeddings_storage_mode, checkpoint, save_final_model, anneal_with_restarts, anneal_with_prestarts, batch_growth_annealing, shuffle, param_selection_mode, write_weights, num_workers, sampler, use_amp, amp_opt_level, eval_on_train_fraction, eval_on_train_shuffle, save_model_at_each_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m                         \u001b[0;31m# forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m                         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m                         \u001b[0;31m# Backward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/flair/models/sequence_tagger_model.py\u001b[0m in \u001b[0;36mforward_loss\u001b[0;34m(self, data_points, sort)\u001b[0m\n\u001b[1;32m    635\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_points\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mSentence\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSentence\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m     ) -> torch.tensor:\n\u001b[0;32m--> 637\u001b[0;31m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_points\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    638\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_calculate_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_points\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/flair/models/sequence_tagger_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, sentences)\u001b[0m\n\u001b[1;32m    640\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mSentence\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 642\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    643\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m         \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/flair/embeddings/base.py\u001b[0m in \u001b[0;36membed\u001b[0;34m(self, sentences)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0meverything_embedded\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatic_embeddings\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_embeddings_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/flair/embeddings/token.py\u001b[0m in \u001b[0;36m_add_embeddings_internal\u001b[0;34m(self, sentences)\u001b[0m\n\u001b[1;32m    927\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_embeddings_to_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 929\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    930\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_add_embeddings_to_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/flair/embeddings/token.py\u001b[0m in \u001b[0;36m_add_embeddings_to_sentence\u001b[0;34m(self, sentence)\u001b[0m\n\u001b[1;32m   1026\u001b[0m                 \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# make the tuple a tensor; makes working with it easier.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1028\u001b[0;31m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# deactivate gradients if not necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1029\u001b[0m                     \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1030\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    967\u001b[0m             \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    968\u001b[0m             \u001b[0minputs_embeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 969\u001b[0;31m             \u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    970\u001b[0m         )\n\u001b[1;32m    971\u001b[0m         encoder_outputs = self.encoder(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds, past_key_values_length)\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_embedding_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"absolute\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m             \u001b[0mposition_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m             \u001b[0membeddings\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mposition_embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayerNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (903) must match the size of tensor b (512) at non-singleton dimension 1"]}]},{"cell_type":"code","metadata":{"id":"uy9VHLh3GhdO","executionInfo":{"status":"aborted","timestamp":1621538532844,"user_tz":180,"elapsed":118189,"user":{"displayName":"A Channel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggz2bYNfS9NrAcTdTQF-N55OWSdO1uRFRXC0UCW=s64","userId":"00910252667657358335"}}},"source":["final = pd.read_csv(\"/content/resources/taggers/nerFinal/test.tsv\", sep = ' ', skip_blank_lines=False,header=None)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vjfORwtmINXF"},"source":["final2 = final"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CzwWBsXFKBfJ"},"source":["final2 = final2.drop(columns=[1,2])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wyvs4NsAKeAt"},"source":["final2['Tag'] = final[2]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bsPojsaGKl9F"},"source":["final2 = final2.drop(columns=[0])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nPmqC1kULrKr","executionInfo":{"status":"ok","timestamp":1621527285534,"user_tz":180,"elapsed":796,"user":{"displayName":"A Channel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggz2bYNfS9NrAcTdTQF-N55OWSdO1uRFRXC0UCW=s64","userId":"00910252667657358335"}},"outputId":"f91f8ab0-47a7-41d3-8edf-925e2287636e"},"source":["final2.index"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["RangeIndex(start=0, stop=14079, step=1)"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"jO2GdougMAZI"},"source":["final2[\"Id\"] = pd.Series(np.arange(start=1, stop=14080, step=1), final2.index)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ovUkxh8rXVp4","executionInfo":{"status":"ok","timestamp":1621527285900,"user_tz":180,"elapsed":515,"user":{"displayName":"A Channel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggz2bYNfS9NrAcTdTQF-N55OWSdO1uRFRXC0UCW=s64","userId":"00910252667657358335"}},"outputId":"afbfa25b-3b13-4fb9-dee0-bf02e6eaf20e"},"source":["cols = final2.columns.tolist()\n","print(cols)\n","cols = cols[-1:] + cols[:-1]\n","print(cols)\n","final2 = final2[cols]"],"execution_count":null,"outputs":[{"output_type":"stream","text":["['Tag', 'Id']\n","['Id', 'Tag']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7qf5gg4CO1yR"},"source":["final2 = final2.dropna()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":979},"id":"ko3iNAjLO8uz","executionInfo":{"status":"ok","timestamp":1621527288560,"user_tz":180,"elapsed":753,"user":{"displayName":"A Channel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggz2bYNfS9NrAcTdTQF-N55OWSdO1uRFRXC0UCW=s64","userId":"00910252667657358335"}},"outputId":"12bfc8f4-bde5-40d1-dba9-1bff9e1a6d3d"},"source":["final2.head(30)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Id</th>\n","      <th>Tag</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>6</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>7</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>8</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>9</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>11</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>12</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>14</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>15</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>16</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>17</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>19</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>20</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>22</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>23</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>25</td>\n","      <td>B-LOCAL</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>26</td>\n","      <td>I-LOCAL</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>27</td>\n","      <td>I-LOCAL</td>\n","    </tr>\n","    <tr>\n","      <th>27</th>\n","      <td>28</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>28</th>\n","      <td>29</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>29</th>\n","      <td>30</td>\n","      <td>B-TEMPO</td>\n","    </tr>\n","    <tr>\n","      <th>30</th>\n","      <td>31</td>\n","      <td>I-TEMPO</td>\n","    </tr>\n","    <tr>\n","      <th>31</th>\n","      <td>32</td>\n","      <td>I-TEMPO</td>\n","    </tr>\n","    <tr>\n","      <th>32</th>\n","      <td>33</td>\n","      <td>I-TEMPO</td>\n","    </tr>\n","    <tr>\n","      <th>33</th>\n","      <td>34</td>\n","      <td>I-TEMPO</td>\n","    </tr>\n","    <tr>\n","      <th>34</th>\n","      <td>35</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>36</th>\n","      <td>37</td>\n","      <td>O</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    Id      Tag\n","0    1        O\n","1    2        O\n","2    3        O\n","4    5        O\n","5    6        O\n","6    7        O\n","7    8        O\n","8    9        O\n","10  11        O\n","11  12        O\n","13  14        O\n","14  15        O\n","15  16        O\n","16  17        O\n","18  19        O\n","19  20        O\n","21  22        O\n","22  23        O\n","24  25  B-LOCAL\n","25  26  I-LOCAL\n","26  27  I-LOCAL\n","27  28        O\n","28  29        O\n","29  30  B-TEMPO\n","30  31  I-TEMPO\n","31  32  I-TEMPO\n","32  33  I-TEMPO\n","33  34  I-TEMPO\n","34  35        O\n","36  37        O"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"l2E2ZF6ZPZIO"},"source":["final2.to_csv('/content/drive/MyDrive/NLP/2_Competição/resultados/stackedWePtStackedLSTM.csv',index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AMz2o3PQwnng","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1621384689566,"user_tz":180,"elapsed":905,"user":{"displayName":"A Channel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggz2bYNfS9NrAcTdTQF-N55OWSdO1uRFRXC0UCW=s64","userId":"00910252667657358335"}},"outputId":"e4f9810d-16f5-4abe-f36b-15826aead4c7"},"source":["from google.colab import files\n","files.download('/content/resources/taggers/example-ner/final-model.pt')"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/javascript":["download(\"download_b8aeb901-86e5-4a55-afe4-585a5fc9ba12\", \"final-model.pt\", 1599842601)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"jCFBU4etDsAB"},"source":[""],"execution_count":null,"outputs":[]}]}